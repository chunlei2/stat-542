x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] = rnorm(1, (n*x_new[2]*y_mean)/(n*x_new[2]+omega), 1/(n*x_new[2]+omega))
x_new[2] = rgamma(1, shape = n/2+alpha, rate = (sum((y-x_new[1])^2)/2+1/beta))
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] = rnorm(1, (n*x_new[2]*y_mean)/(n*x_new[2]+omega), 1/(n*x_new[2]+omega))
c_2 <- 0.5 * sum((y - x_new[1])^2) + 1 / beta
x_new[2] = rgamma(1, shape = n/2+alpha, scale = 1/c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
y <- c(1.9, 3.4, 0.3, 2.5, 2.6); y_bar <- mean(y)
gibbs_sampler <- function(tau_old, y_seq=y, n=5, omega=0.04, alpha=2, beta=0.5){
mu_new <- rnorm(1, (n * tau_old * y_bar) / (n * tau_old + omega), sqrt(1 / (n * tau_old + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y_seq - mu_new)^2) + 1 / beta
tau_new <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(c(mu_new, tau_new))
}
sample_size <- 20000; mu_0 <- 0; tau_0 <- 1
samples <- matrix(ncol=2, nrow=sample_size + 1)
samples[1,] <- c(mu_0, tau_0)
for (i in seq_len(sample_size)){
samples[i+1,] <- gibbs_sampler(tau_old=samples[i,2])
}
samples_accepted <- tail(samples, n/2)
estimator <- apply(samples_accepted, MARGIN=2, mean)
estimator
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] = rnorm(1, (n*x_new[2]*y_mean)/(n*x_new[2]+omega), 1/(n*x_new[2]+omega))
c_2 <- 0.5 * sum((y - x_new[1])^2) + 1 / beta
x_new[2] = rgamma(1, shape = n/2+alpha, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x[1] <- rnorm(1, (n * x[2] * y_mean) / (n * x[2] + omega), sqrt(1 / (n * x[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x[1])^2) + 1 / beta
x[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x[1] <- rnorm(1, (n * x[2] * y_mean) / (n * x[2] + omega), sqrt(1 / (n * x[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x[1])^2) + 1 / beta
x[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] <- rnorm(1, (n * x[2] * y_mean) / (n * x[2] + omega), sqrt(1 / (n * x[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x[1])^2) + 1 / beta
x_new[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] <- rnorm(1, (n * x[2] * y_mean) / (n * x[2] + omega), sqrt(1 / (n * x[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x[1])^2) + 1 / beta
x_new[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] <- rnorm(1, (n * x[2] * y_mean) / (n * x[2] + omega), sqrt(1 / (n * x[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x[1])^2) + 1 / beta
x_new[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] <- rnorm(1, (n * x[2] * y_mean) / (n * x[2] + omega), sqrt(1 / (n * x[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x[1])^2) + 1 / beta
x_new[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] <- rnorm(1, (n * x_new[2] * y_mean) / (n * x_new[2] + omega), sqrt(1 / (n * x_new[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x[1])^2) + 1 / beta
x_new[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] <- rnorm(1, (n * x_new[2] * y_mean) / (n * x_new[2] + omega), sqrt(1 / (n * x_new[2] + omega)))
c_1 <- n / 2 + alpha - 1
c_2 <- 0.5 * sum((y - x_new[1])^2) + 1 / beta
x_new[2] <- rgamma(1, shape=c_1 + 1, scale=1 / c_2)
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] = rnorm(1, (n*x_new[2]*y_mean)/(n*x_new[2]+omega), sqrt1/(n*x_new[2]+omega)))
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] = rnorm(1, (n*x_new[2]*y_mean)/(n*x_new[2]+omega), sqrt1/(n*x_new[2]+omega))
x_new[2] = rgamma(1, shape = n/2+alpha, rate = (sum((y-x_new[1])^2)/2+1/beta))
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
rm(list = ls())
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] = rnorm(1, (n*x_new[2]*y_mean)/(n*x_new[2]+omega), sqrt(1/(n*x_new[2]+omega)))
x_new[2] = rgamma(1, shape = n/2+alpha, rate = (sum((y-x_new[1])^2)/2+1/beta))
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
set.seed(1)
y = c(1.9, 3.4, 0.3, 2.5, 2.6)
n = 5
omega = 0.04
alpha = 2
beta = 0.5
y_mean = mean(y)
t = 20000
x_0 = c(0, 1)
x_matrix = matrix(0, t+1, 2)
x_matrix[1, ] = x_0
gibbs = function(x){
x_new = x
x_new[1] = rnorm(1, (n*x_new[2]*y_mean)/(n*x_new[2]+omega), sqrt(1/(n*x_new[2]+omega)))
x_new[2] = rgamma(1, shape = n/2+alpha, rate = (sum((y-x_new[1])^2)/2+1/beta))
return(x_new)
}
for (i in 1:t) {
x_matrix[i+1, ] = gibbs(x_matrix[i, ])
}
trunc_sample = tail(x_matrix, 10000)
M <- apply(trunc_sample, 2, mean)
M
rm(list = ls())
mydata = read.csv('Coding3_Bonus_Data.csv')
lo.lev <- function(x1, sp){
## YOUR CODE: compute the diagonal entries of the smoother
##             matrix S, stored in vector "lev"
## Tip: check how we compute the smoother matrix
##      for smoothing spline models
n = length(x1)
A = matrix(0, n, n)
for (i in 1:n) {
y = rep(0, n)
y[i] = 1
y_i = loess(y ~ x1, span = sp, control = loess.control(surface = "direct"))$fitted
# mod = loess(y ~ x1, span = sp)
# y_i = predict(mod, mydata)
A[, i] = y_i
}
lev = diag(A)
return(lev)
}
onestep_CV <- function(x1, y1, sp){
## YOUR CODE:
## 1) fit a loess model y1 ~ x1 with span = sp, and extract
##    the corresponding residual vector
## 2) call lo.lev to obtain the diagonal entries of S
## 3) compute LOO-CV and GCV using formula from lecture notes
##    [lec_W5_NonlinearRegression.pdf] page 33.
res = loess(y1 ~ x1, span = sp, control = loess.control(surface = "direct"))$residuals
s = lo.lev(x1, sp)
cv = mean((res/(1-s))^2)
gcv = mean((res/(1-mean(s)))^2)
return(list(cv = cv, gcv = gcv))
}
myCV <- function(x1, y1, span){
## x1, y1: two vectors
## span: a sequence of values for "span"
m = length(span)
cv = rep(0, m)
gcv = rep(0, m)
for(i in 1:m){
tmp = onestep_CV(x1, y1, span[i])
cv[i] = tmp$cv
gcv[i] = tmp$gcv
}
return(list(cv = cv, gcv = gcv))
}
span1 = seq(from = 0.2, by = 0.05, length = 15 )
cv.out = myCV(mydata$x, mydata$y, span1)
cv = cv.out$cv
gcv = cv.out$gcv
cbind(cv, gcv)
rm(list = ls())
mydata = read.csv('Coding3_Bonus_Data.csv')
rm(list = ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
mydata = read.csv('Coding3_Bonus_Data.csv')
lo.lev <- function(x1, sp){
## YOUR CODE: compute the diagonal entries of the smoother
##             matrix S, stored in vector "lev"
## Tip: check how we compute the smoother matrix
##      for smoothing spline models
n = length(x1)
A = matrix(0, n, n)
for (i in 1:n) {
y = rep(0, n)
y[i] = 1
y_i = loess(y ~ x1, span = sp, control = loess.control(surface = "direct"))$fitted
# mod = loess(y ~ x1, span = sp)
# y_i = predict(mod, mydata)
A[, i] = y_i
}
lev = diag(A)
return(lev)
}
onestep_CV <- function(x1, y1, sp){
## YOUR CODE:
## 1) fit a loess model y1 ~ x1 with span = sp, and extract
##    the corresponding residual vector
## 2) call lo.lev to obtain the diagonal entries of S
## 3) compute LOO-CV and GCV using formula from lecture notes
##    [lec_W5_NonlinearRegression.pdf] page 33.
res = loess(y1 ~ x1, span = sp, control = loess.control(surface = "direct"))$residuals
s = lo.lev(x1, sp)
cv = mean((res/(1-s))^2)
gcv = mean((res/(1-mean(s)))^2)
return(list(cv = cv, gcv = gcv))
}
myCV <- function(x1, y1, span){
## x1, y1: two vectors
## span: a sequence of values for "span"
m = length(span)
cv = rep(0, m)
gcv = rep(0, m)
for(i in 1:m){
tmp = onestep_CV(x1, y1, span[i])
cv[i] = tmp$cv
gcv[i] = tmp$gcv
}
return(list(cv = cv, gcv = gcv))
}
span1 = seq(from = 0.2, by = 0.05, length = 15 )
cv.out = myCV(mydata$x, mydata$y, span1)
cv = cv.out$cv
gcv = cv.out$gcv
cbind(cv, gcv)
rm(list = ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
mydata = read.csv('Coding3_Bonus_Data.csv')
lo.lev <- function(x1, sp){
## YOUR CODE: compute the diagonal entries of the smoother
##             matrix S, stored in vector "lev"
## Tip: check how we compute the smoother matrix
##      for smoothing spline models
n = length(x1)
A = matrix(0, n, n)
for (i in 1:n) {
y = rep(0, n)
y[i] = 1
y_i = loess(y ~ x1, span = sp, control = loess.control(surface = "direct"))$fitted
# mod = loess(y ~ x1, span = sp)
# y_i = predict(mod, mydata)
A[, i] = y_i
}
lev = diag(A)
return(lev)
}
onestep_CV <- function(x1, y1, sp){
## YOUR CODE:
## 1) fit a loess model y1 ~ x1 with span = sp, and extract
##    the corresponding residual vector
## 2) call lo.lev to obtain the diagonal entries of S
## 3) compute LOO-CV and GCV using formula from lecture notes
##    [lec_W5_NonlinearRegression.pdf] page 33.
res = loess(y1 ~ x1, span = sp, control = loess.control(surface = "direct"))$residuals
s = lo.lev(x1, sp)
cv = mean((res/(1-s))^2)
gcv = mean((res/(1-mean(s)))^2)
return(list(cv = cv, gcv = gcv))
}
myCV <- function(x1, y1, span){
## x1, y1: two vectors
## span: a sequence of values for "span"
m = length(span)
cv = rep(0, m)
gcv = rep(0, m)
for(i in 1:m){
tmp = onestep_CV(x1, y1, span[i])
cv[i] = tmp$cv
gcv[i] = tmp$gcv
}
return(list(cv = cv, gcv = gcv))
}
span1 = seq(from = 0.2, by = 0.05, length = 15 )
cv.out = myCV(mydata$x, mydata$y, span1)
cv = cv.out$cv
gcv = cv.out$gcv
cbind(cv, gcv)
